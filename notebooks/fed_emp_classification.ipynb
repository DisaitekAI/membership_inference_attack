{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path('../data/')\n",
    "df        = pd.read_csv(data_path / 'interim' / 'fed_emp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the lines for which the target in unknown\n",
    "df                                   = df[~df.EDLVL.isnull()]\n",
    "# Removing the nan values in columns by either adding a new category\n",
    "# or dropping the lines\n",
    "df.loc[df.GSEGRD.isnull(), 'GSEGRD'] = 0\n",
    "df.loc[df.OCC.isnull(), 'OCC']       = 0\n",
    "df                                   = df[~df.SUPERVIS.isnull()]\n",
    "df                                   = df[~df.TOA.isnull()]\n",
    "df                                   = df[~df.SALARY.isnull()]\n",
    "df                                   = df[~df.LOS.isnull()]\n",
    "# df.isnull().sum(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f4185068a20>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_data    = df.drop(['EDLVL'], axis = 1)\n",
    "df_target  = df['EDLVL']\n",
    "df_target  = df_target - 1 # Values between 0 and 21 instead of 1 and 22\n",
    "# df_target.hist(bins = 22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns = ['SALARY', 'LOS']\n",
    "df_num            = df_data[numerical_columns]\n",
    "df_cat            = df_data.drop(numerical_columns, axis = 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_encoders = {\n",
    "    col : {\n",
    "        val : i \n",
    "        for i, val in enumerate(df[col].unique())\n",
    "    }\n",
    "    for col in df_cat.columns\n",
    "}\n",
    "column_order = list(columns_encoders.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df_cat.columns:\n",
    "    df_cat[col] = df_cat[col].apply(lambda x: columns_encoders[col][x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CategoricalEmbeddings(nn.Module):\n",
    "    def __init__(self, col_order, col_encoders, col_to_emb_dim):\n",
    "        super(CategoricalEmbeddings, self).__init__()\n",
    "        self.col_order = col_order \n",
    "        self.cat_embs  = nn.ModuleDict({\n",
    "            col: nn.Embedding(len(col_encoders[col]), col_to_emb_dim[col])\n",
    "            for col in col_order\n",
    "        })\n",
    "        \n",
    "    def forward(self, cat_variables):\n",
    "        embeddings = [self.cat_embs[col](cat_variables[col]) for col in self.col_order]\n",
    "        \n",
    "        return torch.cat(embeddings, dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EdlvlClassifier(nn.Module):\n",
    "    def __init__(self, col_order, col_encoders, col_to_emb_dim):\n",
    "        super(EdlvlClassifier, self).__init__()\n",
    "        self.cat_emb    = CategoricalEmbeddings(col_order, col_encoders, col_to_emb_dim)\n",
    "        sum_cat_emb_dim = sum(col_to_emb_dim.values())\n",
    "        self.linear1    = nn.Linear(sum_cat_emb_dim + 2, 128)\n",
    "        self.linear2    = nn.Linear(128, 22)\n",
    "        \n",
    "    def forward(self, cat_variables, num_variables):\n",
    "#         import pdb\n",
    "#         pdb.set_trace()\n",
    "        cat_embeddings = self.cat_emb(cat_variables)\n",
    "        cat_num_tensor = torch.cat([cat_embeddings, num_variables], dim = 1)\n",
    "        out_linear1    = F.relu(self.linear1(cat_num_tensor))\n",
    "        out_linear2    = self.linear2(out_linear1)\n",
    "        \n",
    "        return out_linear2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EdlvlClassifier(\n",
       "  (cat_emb): CategoricalEmbeddings(\n",
       "    (cat_embs): ModuleDict(\n",
       "      (AGELVL): Embedding(12, 2)\n",
       "      (AGYSUB): Embedding(523, 2)\n",
       "      (GSEGRD): Embedding(16, 2)\n",
       "      (LOC): Embedding(219, 2)\n",
       "      (LOSLVL): Embedding(10, 2)\n",
       "      (OCC): Embedding(656, 2)\n",
       "      (PATCO): Embedding(7, 2)\n",
       "      (PPGRD): Embedding(933, 2)\n",
       "      (SALLVL): Embedding(25, 2)\n",
       "      (STEMOCC): Embedding(100, 2)\n",
       "      (SUPERVIS): Embedding(6, 2)\n",
       "      (TOA): Embedding(18, 2)\n",
       "      (WORKSCH): Embedding(10, 2)\n",
       "      (WORKSTAT): Embedding(2, 2)\n",
       "    )\n",
       "  )\n",
       "  (linear1): Linear(in_features=30, out_features=128, bias=True)\n",
       "  (linear2): Linear(in_features=128, out_features=22, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = EdlvlClassifier(\n",
    "    column_order,\n",
    "    columns_encoders,\n",
    "    {\n",
    "        col : 2\n",
    "        for col in columns_encoders\n",
    "    }\n",
    ")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TensorDataset(\n",
    "    *[\n",
    "        torch.tensor(df_cat[col].values)\n",
    "        for col in column_order\n",
    "    ], # categorical variables in the correct order\n",
    "    torch.tensor(df_num.values, dtype = torch.float32), # numerical variables\n",
    "    torch.tensor(df_target.values, dtype = torch.int32) # target variables\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(dataset, batch_size = 16, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for *cat_var_list, num_var, y in loader:\n",
    "    cat_variables = dict(zip(column_order, cat_var_list))\n",
    "    res = model(cat_variables, num_var)\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
