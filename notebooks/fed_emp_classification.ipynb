{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path('../data/')\n",
    "df        = pd.read_csv(data_path / 'interim' / 'fed_emp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the lines for which the target in unknown\n",
    "df                                   = df[~df.EDLVL.isnull()]\n",
    "# Removing the nan values in columns by either adding a new category\n",
    "# or dropping the lines\n",
    "df.loc[df.GSEGRD.isnull(), 'GSEGRD'] = 0\n",
    "df.loc[df.OCC.isnull(), 'OCC']       = 0\n",
    "df                                   = df[~df.SUPERVIS.isnull()]\n",
    "df                                   = df[~df.TOA.isnull()]\n",
    "df                                   = df[~df.SALARY.isnull()]\n",
    "df                                   = df[~df.LOS.isnull()]\n",
    "# df.isnull().sum(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data    = df.drop(['EDLVL'], axis = 1)\n",
    "df_target  = df['EDLVL']\n",
    "df_target  = df_target - 1 # Values between 0 and 21 instead of 1 and 22\n",
    "# df_target.hist(bins = 22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns = ['SALARY', 'LOS']\n",
    "df_num            = df_data[numerical_columns]\n",
    "num_val_mean      = df_num.mean(axis = 0)\n",
    "num_val_std       = df_num.std(axis = 0)\n",
    "df_num            = (df_num - num_val_mean) / num_val_std\n",
    "df_cat            = df_data.drop(numerical_columns, axis = 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_encoders = {\n",
    "    col : {\n",
    "        val : i \n",
    "        for i, val in enumerate(df[col].unique())\n",
    "    }\n",
    "    for col in df_cat.columns\n",
    "}\n",
    "column_order = list(columns_encoders.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df_cat.columns:\n",
    "    df_cat[col] = df_cat[col].apply(lambda x: columns_encoders[col][x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CategoricalEmbeddings(nn.Module):\n",
    "    def __init__(self, col_order, col_encoders, col_to_emb_dim):\n",
    "        super(CategoricalEmbeddings, self).__init__()\n",
    "        self.col_order = col_order \n",
    "        self.cat_embs  = nn.ModuleDict({\n",
    "            col: nn.Embedding(len(col_encoders[col]), col_to_emb_dim[col])\n",
    "            for col in col_order\n",
    "        })\n",
    "        \n",
    "    def forward(self, cat_variables):\n",
    "        embeddings = [self.cat_embs[col](cat_variables[col]) for col in self.col_order]\n",
    "        \n",
    "        return torch.cat(embeddings, dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EdlvlClassifier(nn.Module):\n",
    "    def __init__(self, col_order, col_encoders, col_to_emb_dim, lin_size = 256, dropout_rate = 0.2):\n",
    "        super(EdlvlClassifier, self).__init__()\n",
    "        self.cat_emb    = CategoricalEmbeddings(col_order, col_encoders, col_to_emb_dim)\n",
    "        sum_cat_emb_dim = sum(col_to_emb_dim.values())\n",
    "        self.linear1    = nn.Linear(sum_cat_emb_dim + 2, lin_size)\n",
    "        self.linear2    = nn.Linear(lin_size, 22)\n",
    "        self.dropout    = nn.Dropout(dropout_rate)\n",
    "        \n",
    "    def forward(self, cat_variables, num_variables):\n",
    "        cat_embeddings = self.cat_emb(cat_variables)\n",
    "        cat_num_tensor = torch.cat([cat_embeddings, num_variables], dim = 1)\n",
    "        cat_num_tensor = self.dropout(cat_num_tensor)\n",
    "        out_linear1    = F.relu(self.dropout(self.linear1(cat_num_tensor)))\n",
    "        out_linear2    = self.linear2(out_linear1)\n",
    "        \n",
    "        return out_linear2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EdlvlClassifier(\n",
       "  (cat_emb): CategoricalEmbeddings(\n",
       "    (cat_embs): ModuleDict(\n",
       "      (AGELVL): Embedding(12, 4)\n",
       "      (AGYSUB): Embedding(523, 4)\n",
       "      (GSEGRD): Embedding(16, 4)\n",
       "      (LOC): Embedding(219, 4)\n",
       "      (LOSLVL): Embedding(10, 4)\n",
       "      (OCC): Embedding(656, 4)\n",
       "      (PATCO): Embedding(7, 4)\n",
       "      (PPGRD): Embedding(933, 4)\n",
       "      (SALLVL): Embedding(25, 4)\n",
       "      (STEMOCC): Embedding(100, 4)\n",
       "      (SUPERVIS): Embedding(6, 4)\n",
       "      (TOA): Embedding(18, 4)\n",
       "      (WORKSCH): Embedding(10, 4)\n",
       "      (WORKSTAT): Embedding(2, 4)\n",
       "    )\n",
       "  )\n",
       "  (linear1): Linear(in_features=58, out_features=256, bias=True)\n",
       "  (linear2): Linear(in_features=256, out_features=22, bias=True)\n",
       "  (dropout): Dropout(p=0.2)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = EdlvlClassifier(\n",
    "    column_order,\n",
    "    columns_encoders,\n",
    "    {\n",
    "        col : 4\n",
    "        for col in columns_encoders\n",
    "    }\n",
    ")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TensorDataset(\n",
    "    *[\n",
    "        torch.tensor(df_cat[col].values)\n",
    "        for col in column_order\n",
    "    ], # categorical variables in the correct order\n",
    "    torch.tensor(df_num.values, dtype = torch.float32), # numerical variables\n",
    "    torch.tensor(df_target.values, dtype = torch.int64) # target variables\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_size                 = len(dataset)\n",
    "valid_prop                   = 0.2\n",
    "valid_size                   = round(valid_prop * dataset_size)\n",
    "lengths                      = [dataset_size - valid_size, valid_size]\n",
    "train_dataset, valid_dataset = random_split(dataset, lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "device       = torch.device('cuda')\n",
    "model        = model.to(device)\n",
    "epochs       = 20\n",
    "batch_size   = 2048\n",
    "optimizer    = optim.Adam(model.parameters())\n",
    "criterion    = nn.CrossEntropyLoss()\n",
    "train_loader = DataLoader(train_dataset, batch_size = batch_size, shuffle = True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size = batch_size, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56826 362579\n",
      "[0:0] [T]  5.96%, [V] 15.67%  3.06\n",
      "166021 362579\n",
      "[0:300] [T] 40.04%, [V] 45.79%  1.73\n",
      "170166 362579\n",
      "[0:600] [T] 42.26%, [V] 46.93%  1.67\n",
      "171534 362579\n",
      "[1:0] [T] 47.41%, [V] 47.31%  1.63\n",
      "173776 362579\n",
      "[1:300] [T] 46.09%, [V] 47.93%  1.63\n",
      "174963 362579\n",
      "[1:600] [T] 46.40%, [V] 48.26%  1.64\n",
      "175415 362579\n",
      "[2:0] [T] 48.34%, [V] 48.38%  1.65\n",
      "176260 362579\n",
      "[2:300] [T] 47.19%, [V] 48.61%  1.63\n",
      "177352 362579\n",
      "[2:600] [T] 47.35%, [V] 48.91%  1.59\n",
      "177511 362579\n",
      "[3:0] [T] 49.61%, [V] 48.96%  1.55\n",
      "178011 362579\n",
      "[3:300] [T] 47.84%, [V] 49.10%  1.59\n",
      "178762 362579\n",
      "[3:600] [T] 47.89%, [V] 49.30%  1.58\n",
      "178623 362579\n",
      "[4:0] [T] 48.78%, [V] 49.26%  1.58\n",
      "179168 362579\n",
      "[4:300] [T] 48.22%, [V] 49.41%  1.55\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    correct = 0\n",
    "    total   = 0\n",
    "    for i, (*cat_var_list, num_var, y) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        cat_var_list   = [t.to(device) for t in cat_var_list]\n",
    "        num_var        = num_var.to(device)\n",
    "        y              = y.to(device)\n",
    "        cat_variables  = dict(zip(column_order, cat_var_list))\n",
    "        res            = model(cat_variables, num_var)\n",
    "        loss           = criterion(res, y)\n",
    "        correct       += (res.argmax(dim = 1) == y).detach().sum().item()\n",
    "        total         += y.shape[0]\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if i % 300 == 0: \n",
    "            model.eval()\n",
    "            valid_correct = 0\n",
    "            valid_total   = 0\n",
    "            with torch.no_grad():\n",
    "                for *cat_var_list, num_var, y in valid_loader:\n",
    "                    cat_var_list   = [t.to(device) for t in cat_var_list]\n",
    "                    num_var        = num_var.to(device)\n",
    "                    y              = y.to(device)\n",
    "                    cat_variables  = dict(zip(column_order, cat_var_list))\n",
    "                    res            = model(cat_variables, num_var)\n",
    "                    valid_correct += (res.argmax(dim = 1) == y).detach().sum().item()\n",
    "                    valid_total   += y.shape[0]\n",
    "            print(valid_correct, valid_total)\n",
    "            print(f'[{epoch}:{i}] [T] {100. * correct / total:5.2f}%, [V] {100. * valid_correct / valid_total:5.2f}% {loss.item():5.2f}')\n",
    "            model.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
