{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path('../data/')\n",
    "df        = pd.read_csv(data_path / 'interim' / 'fed_emp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the lines for which the target in unknown\n",
    "df                                   = df[~df.EDLVL.isnull()]\n",
    "# Removing the nan values in columns by either adding a new category\n",
    "# or dropping the lines\n",
    "df.loc[df.GSEGRD.isnull(), 'GSEGRD'] = 0\n",
    "df.loc[df.OCC.isnull(), 'OCC']       = 0\n",
    "df                                   = df[~df.SUPERVIS.isnull()]\n",
    "df                                   = df[~df.TOA.isnull()]\n",
    "df                                   = df[~df.SALARY.isnull()]\n",
    "df                                   = df[~df.LOS.isnull()]\n",
    "# df.isnull().sum(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data    = df.drop(['EDLVL'], axis = 1)\n",
    "df_target  = df['EDLVL']\n",
    "df_target  = df_target - 1 # Values between 0 and 21 instead of 1 and 22\n",
    "# df_target.hist(bins = 22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns = ['SALARY', 'LOS']\n",
    "df_num            = df_data[numerical_columns]\n",
    "df_cat            = df_data.drop(numerical_columns, axis = 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_encoders = {\n",
    "    col : {\n",
    "        val : i \n",
    "        for i, val in enumerate(df[col].unique())\n",
    "    }\n",
    "    for col in df_cat.columns\n",
    "}\n",
    "column_order = list(columns_encoders.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df_cat.columns:\n",
    "    df_cat[col] = df_cat[col].apply(lambda x: columns_encoders[col][x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CategoricalEmbeddings(nn.Module):\n",
    "    def __init__(self, col_order, col_encoders, col_to_emb_dim):\n",
    "        super(CategoricalEmbeddings, self).__init__()\n",
    "        self.col_order = col_order \n",
    "        self.cat_embs  = nn.ModuleDict({\n",
    "            col: nn.Embedding(len(col_encoders[col]), col_to_emb_dim[col])\n",
    "            for col in col_order\n",
    "        })\n",
    "        \n",
    "    def forward(self, cat_variables):\n",
    "        embeddings = [self.cat_embs[col](cat_variables[col]) for col in self.col_order]\n",
    "        \n",
    "        return torch.cat(embeddings, dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EdlvlClassifier(nn.Module):\n",
    "    def __init__(self, col_order, col_encoders, col_to_emb_dim):\n",
    "        super(EdlvlClassifier, self).__init__()\n",
    "        self.cat_emb    = CategoricalEmbeddings(col_order, col_encoders, col_to_emb_dim)\n",
    "        sum_cat_emb_dim = sum(col_to_emb_dim.values())\n",
    "        self.linear1    = nn.Linear(sum_cat_emb_dim + 2, 128)\n",
    "        self.linear2    = nn.Linear(128, 22)\n",
    "        \n",
    "    def forward(self, cat_variables, num_variables):\n",
    "#         import pdb\n",
    "#         pdb.set_trace()\n",
    "        cat_embeddings = self.cat_emb(cat_variables)\n",
    "        cat_num_tensor = torch.cat([cat_embeddings, num_variables], dim = 1)\n",
    "        out_linear1    = F.relu(self.linear1(cat_num_tensor))\n",
    "        out_linear2    = self.linear2(out_linear1)\n",
    "        \n",
    "        return out_linear2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EdlvlClassifier(\n",
       "  (cat_emb): CategoricalEmbeddings(\n",
       "    (cat_embs): ModuleDict(\n",
       "      (AGELVL): Embedding(12, 2)\n",
       "      (AGYSUB): Embedding(523, 2)\n",
       "      (GSEGRD): Embedding(16, 2)\n",
       "      (LOC): Embedding(219, 2)\n",
       "      (LOSLVL): Embedding(10, 2)\n",
       "      (OCC): Embedding(656, 2)\n",
       "      (PATCO): Embedding(7, 2)\n",
       "      (PPGRD): Embedding(933, 2)\n",
       "      (SALLVL): Embedding(25, 2)\n",
       "      (STEMOCC): Embedding(100, 2)\n",
       "      (SUPERVIS): Embedding(6, 2)\n",
       "      (TOA): Embedding(18, 2)\n",
       "      (WORKSCH): Embedding(10, 2)\n",
       "      (WORKSTAT): Embedding(2, 2)\n",
       "    )\n",
       "  )\n",
       "  (linear1): Linear(in_features=30, out_features=128, bias=True)\n",
       "  (linear2): Linear(in_features=128, out_features=22, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = EdlvlClassifier(\n",
    "    column_order,\n",
    "    columns_encoders,\n",
    "    {\n",
    "        col : 2\n",
    "        for col in columns_encoders\n",
    "    }\n",
    ")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TensorDataset(\n",
    "    *[\n",
    "        torch.tensor(df_cat[col].values)\n",
    "        for col in column_order\n",
    "    ], # categorical variables in the correct order\n",
    "    torch.tensor(df_num.values, dtype = torch.float32), # numerical variables\n",
    "    torch.tensor(df_target.values, dtype = torch.int64) # target variables\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(dataset, batch_size = 16, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs     = 5\n",
    "batch_size = 256\n",
    "optimizer  = optim.Adam(model.parameters())\n",
    "criterion  = nn.CrossEntropyLoss()\n",
    "loader     = DataLoader(dataset, batch_size = batch_size, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0:0] 8%, 6119.14208984375\n",
      "[0:300] 21%, 379.6171569824219\n",
      "[0:600] 24%, 104.51863098144531\n",
      "[0:900] 24%, 499.3503112792969\n",
      "[0:1200] 24%, 245.5634765625\n",
      "[0:1500] 23%, 250.1242218017578\n",
      "[0:1800] 25%, 226.1015625\n",
      "[0:2100] 25%, 103.34579467773438\n",
      "[0:2400] 25%, 116.79896545410156\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-dc813725e52e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mcorrect\u001b[0m       \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mtotal\u001b[0m         \u001b[0;34m+=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m300\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/memb_inf_attack/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \"\"\"\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/memb_inf_attack/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    correct = 0\n",
    "    total   = 0\n",
    "    for i, (*cat_var_list, num_var, y) in enumerate(loader):\n",
    "        optimizer.zero_grad()\n",
    "        cat_variables  = dict(zip(column_order, cat_var_list))\n",
    "        res            = model(cat_variables, num_var)\n",
    "        loss           = criterion(res, y)\n",
    "        correct       += (res.argmax(dim = 1) == y).detach().sum()\n",
    "        total         += y.shape[0]\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if i % 300 == 0: \n",
    "            print(f'[{epoch}:{i}] {100 * correct / total}%, {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.argmax(dim = 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
